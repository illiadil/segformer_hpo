{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/illiadil/segformer_hpo/blob/main/experiment_segformer_hpo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a60204b3",
        "outputId": "a507a8bc-99b3-4e63-d354-d9a614641391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'segformer_hpo'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 22 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (22/22), 16.14 KiB | 5.38 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/illiadil/segformer_hpo"
      ],
      "id": "a60204b3"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90c3814b",
        "outputId": "992368fa-02a2-4103-be17-c6ac57ff1c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/segformer_hpo\n"
          ]
        }
      ],
      "source": [
        "cd segformer_hpo"
      ],
      "id": "90c3814b"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0ab1935e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9cc073f-dbad-4735-cc05-daefde888d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.color import rgba2rgb\n",
        "from models import SegFormer_B0"
      ],
      "id": "0ab1935e"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uxFvPxmO_i3O"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 640\n",
        "IMG_HEIGHT = 480\n",
        "IMG_CHANNELS = 3\n",
        "DATASET_SIZE = 200\n",
        "\n",
        "X = np.zeros((DATASET_SIZE, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "y = np.zeros((DATASET_SIZE, IMG_HEIGHT, IMG_WIDTH, 1), dtype=float)\n",
        "\n",
        "for i in range(1,DATASET_SIZE):\n",
        "  image = imread(\"/content/drive/MyDrive/PhD/label_tool/dataset/images/\"+str(i).zfill(5)+\".png\")[:,:,:3]\n",
        "  mask_ = imread(\"/content/drive/MyDrive/PhD/label_tool/dataset/masks/\"+str(i).zfill(5)+\"_mask.png\")\n",
        "  X[i] = image\n",
        "  mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "  mask_ = np.expand_dims(mask_, axis=-1)\n",
        "  mask = np.maximum(mask, mask_[:,:,1])\n",
        "  y[i] = mask / 255"
      ],
      "id": "uxFvPxmO_i3O"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M5eO5ROR_tL3"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
      ],
      "id": "M5eO5ROR_tL3"
    },
    {
      "cell_type": "code",
      "source": [
        "lr_schedule_exponential = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "lr_schedule_polynomial = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=10000,\n",
        "    end_learning_rate=0.0001,\n",
        "    power=1.0,\n",
        "    cycle=False,\n",
        "    name=None,\n",
        ")"
      ],
      "metadata": {
        "id": "YAqEOYerzOCd"
      },
      "id": "YAqEOYerzOCd",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam_exponential = tf.keras.optimizers.experimental.Adam()#lr_schedule_exponential)\n",
        "rmsprop_exponential = tf.keras.optimizers.experimental.RMSprop()#lr_schedule_exponential)\n",
        "sgd_exponential = tf.keras.optimizers.experimental.SGD()#lr_schedule_exponential)\n",
        "\n",
        "adam_polynomial = tf.keras.optimizers.experimental.Adam()#lr_schedule_polynomial)\n",
        "rmsprop_polynomial = tf.keras.optimizers.experimental.RMSprop()#lr_schedule_polynomial)\n",
        "sgd_polynomial = tf.keras.optimizers.experimental.SGD()#lr_schedule_polynomial)"
      ],
      "metadata": {
        "id": "chECtoHgzvjt"
      },
      "id": "chECtoHgzvjt",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(y_true, y_pred):\n",
        "  threshold = 0.8\n",
        "  y_prediction = y_pred[:,:,1] > threshold\n",
        "  y_ground_truth = y_true[:,:,0] > 0.5\n",
        "  TP = (y_prediction == y_ground_truth)\n",
        "  FN_and_FP = (y_ground_truth != y_prediction)\n",
        "  TP_sum = float(tf.reduce_sum(tf.cast(TP, tf.float32)))\n",
        "  FN_and_FP_sum = float(tf.reduce_sum(tf.cast(FN_and_FP, tf.float32)))\n",
        "  return TP_sum/( TP_sum + FN_and_FP_sum)"
      ],
      "metadata": {
        "id": "BlqL5dz-swd3"
      },
      "id": "BlqL5dz-swd3",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yJ5Ew6iYyKtM"
      },
      "outputs": [],
      "source": [
        "def calculate_miou(mdl):\n",
        "  threshold = 0.8\n",
        "  total_iou = 0\n",
        "  y_predictions = mdl.predict(X_test)\n",
        "  for i in range(X_test.shape[0]):\n",
        "    y_ground_truth = y_test[i]\n",
        "    y_prediction = np.argmax(y_predictions[i], axis=-1)\n",
        "    TP = (y_prediction == y_ground_truth[:,:,0])\n",
        "    FN_and_FP = (y_ground_truth[:,:,0] != y_prediction)\n",
        "    iou = TP.sum()/( TP.sum() + FN_and_FP.sum() )\n",
        "    total_iou = total_iou + iou\n",
        "  average_iou = total_iou / X_test.shape[0]*100\n",
        "  return \"{:.2f}\".format(average_iou)"
      ],
      "id": "yJ5Ew6iYyKtM"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "90cb1e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4cb7a84c-d7eb-4624-dafe-9cdc5115a1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "9/9 [==============================] - 31s 2s/step - loss: 1.5123 - accuracy: 0.6382 - val_loss: 1.3178 - val_accuracy: 0.6961 - lr: 0.0100\n",
            "Epoch 2/15\n",
            "9/9 [==============================] - 8s 947ms/step - loss: 0.7022 - accuracy: 0.6892 - val_loss: 1.2052 - val_accuracy: 0.7924 - lr: 0.0099\n",
            "Epoch 3/15\n",
            "9/9 [==============================] - 8s 952ms/step - loss: 0.6240 - accuracy: 0.7074 - val_loss: 4.6863 - val_accuracy: 0.8190 - lr: 0.0098\n",
            "Epoch 4/15\n",
            "9/9 [==============================] - 9s 962ms/step - loss: 0.6040 - accuracy: 0.7070 - val_loss: 2.5251 - val_accuracy: 0.8190 - lr: 0.0096\n",
            "Epoch 5/15\n",
            "9/9 [==============================] - 8s 945ms/step - loss: 0.6052 - accuracy: 0.7066 - val_loss: 1.5548 - val_accuracy: 0.8024 - lr: 0.0094\n",
            "Epoch 6/15\n",
            "9/9 [==============================] - 8s 879ms/step - loss: 0.5949 - accuracy: 0.7077 - val_loss: 1.3939 - val_accuracy: 0.8180 - lr: 0.0091\n",
            "Epoch 7/15\n",
            "9/9 [==============================] - 8s 948ms/step - loss: 0.5890 - accuracy: 0.7082 - val_loss: 0.7903 - val_accuracy: 0.8190 - lr: 0.0087\n",
            "Epoch 8/15\n",
            "9/9 [==============================] - 8s 940ms/step - loss: 0.5937 - accuracy: 0.7081 - val_loss: 0.5495 - val_accuracy: 0.8230 - lr: 0.0083\n",
            "Epoch 9/15\n",
            "9/9 [==============================] - 8s 873ms/step - loss: 0.5975 - accuracy: 0.7089 - val_loss: 0.5880 - val_accuracy: 0.7176 - lr: 0.0079\n",
            "Epoch 10/15\n",
            "9/9 [==============================] - 8s 867ms/step - loss: 0.5835 - accuracy: 0.7023 - val_loss: 0.6080 - val_accuracy: 0.8190 - lr: 0.0075\n",
            "Epoch 11/15\n",
            "9/9 [==============================] - 8s 954ms/step - loss: 0.5899 - accuracy: 0.7082 - val_loss: 0.4617 - val_accuracy: 0.8190 - lr: 0.0070\n",
            "Epoch 12/15\n",
            "9/9 [==============================] - 8s 946ms/step - loss: 0.5904 - accuracy: 0.7093 - val_loss: 1.8520 - val_accuracy: 0.2061 - lr: 0.0065\n",
            "Epoch 13/15\n",
            "9/9 [==============================] - 8s 874ms/step - loss: 0.5814 - accuracy: 0.7132 - val_loss: 0.9754 - val_accuracy: 0.3265 - lr: 0.0060\n",
            "Epoch 14/15\n",
            "9/9 [==============================] - 8s 880ms/step - loss: 0.5913 - accuracy: 0.7125 - val_loss: 0.4981 - val_accuracy: 0.8462 - lr: 0.0055\n",
            "Epoch 15/15\n",
            "9/9 [==============================] - 8s 942ms/step - loss: 0.5831 - accuracy: 0.7085 - val_loss: 0.4696 - val_accuracy: 0.8420 - lr: 0.0051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79ea972dfe20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 5s 183ms/step\n",
            "Linear : Adam -> mIoU : 74.35%\n",
            "Epoch 1/15\n",
            "9/9 [==============================] - 37s 2s/step - loss: 1.2325 - accuracy: 0.6569 - val_loss: 0.8958 - val_accuracy: 0.7636 - lr: 0.0100\n",
            "Epoch 2/15\n",
            "9/9 [==============================] - 8s 944ms/step - loss: 0.6784 - accuracy: 0.6859 - val_loss: 0.8652 - val_accuracy: 0.7784 - lr: 0.0099\n",
            "Epoch 3/15\n",
            "9/9 [==============================] - 8s 887ms/step - loss: 0.7148 - accuracy: 0.6948 - val_loss: 0.9430 - val_accuracy: 0.8190 - lr: 0.0098\n",
            "Epoch 4/15\n",
            "9/9 [==============================] - 9s 959ms/step - loss: 0.6783 - accuracy: 0.6992 - val_loss: 2.0488 - val_accuracy: 0.1853 - lr: 0.0096\n",
            "Epoch 5/15\n",
            "9/9 [==============================] - 9s 959ms/step - loss: 0.7738 - accuracy: 0.6355 - val_loss: 0.5758 - val_accuracy: 0.8190 - lr: 0.0094\n",
            "Epoch 6/15\n",
            "9/9 [==============================] - 8s 887ms/step - loss: 0.6353 - accuracy: 0.7065 - val_loss: 0.6528 - val_accuracy: 0.7548 - lr: 0.0091\n",
            "Epoch 7/15\n",
            "9/9 [==============================] - 8s 947ms/step - loss: 0.6898 - accuracy: 0.6965 - val_loss: 3.2177 - val_accuracy: 0.8190 - lr: 0.0087\n",
            "Epoch 8/15\n",
            "9/9 [==============================] - 8s 882ms/step - loss: 0.6334 - accuracy: 0.7075 - val_loss: 1.2104 - val_accuracy: 0.8190 - lr: 0.0083\n",
            "Epoch 9/15\n",
            "9/9 [==============================] - 8s 949ms/step - loss: 0.7011 - accuracy: 0.6513 - val_loss: 0.7822 - val_accuracy: 0.7625 - lr: 0.0079\n",
            "Epoch 10/15\n",
            "9/9 [==============================] - 8s 874ms/step - loss: 0.6644 - accuracy: 0.6967 - val_loss: 0.6587 - val_accuracy: 0.7391 - lr: 0.0075\n",
            "Epoch 11/15\n",
            "9/9 [==============================] - 8s 880ms/step - loss: 0.6416 - accuracy: 0.6933 - val_loss: 0.5323 - val_accuracy: 0.8175 - lr: 0.0070\n",
            "Epoch 12/15\n",
            "9/9 [==============================] - 8s 949ms/step - loss: 0.6278 - accuracy: 0.6998 - val_loss: 1.0552 - val_accuracy: 0.8190 - lr: 0.0065\n",
            "Epoch 13/15\n",
            "9/9 [==============================] - 9s 955ms/step - loss: 0.6268 - accuracy: 0.7029 - val_loss: 1.7207 - val_accuracy: 0.1810 - lr: 0.0060\n",
            "Epoch 14/15\n",
            "9/9 [==============================] - 8s 887ms/step - loss: 0.6496 - accuracy: 0.6985 - val_loss: 1.5338 - val_accuracy: 0.1810 - lr: 0.0055\n",
            "Epoch 15/15\n",
            "9/9 [==============================] - 8s 948ms/step - loss: 0.6154 - accuracy: 0.7056 - val_loss: 0.5099 - val_accuracy: 0.8190 - lr: 0.0051\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-26fe3e84d2da>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"segformer_b0_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moptimizers_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdecays_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmiou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_miou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mmiou_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmiou\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecays_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" : \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0moptimizers_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\" -> mIoU : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmiou\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-cdbee8482c9c>\u001b[0m in \u001b[0;36mcalculate_miou\u001b[0;34m(mdl)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtotal_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0my_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_ground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOOM when allocating tensor with shape[32,1024,120,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_7/seg_former_head_7/conv_module_7/conv2d_78/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_259344]"
          ]
        }
      ],
      "source": [
        "from keras.optimizers.legacy import Adam, SGD, RMSprop\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "\n",
        "# Define initial learning rate\n",
        "initial_learning_rate = 0.01\n",
        "# Define decay steps\n",
        "decay_steps = 15\n",
        "# Define decay rate\n",
        "decay_rate = 0.1\n",
        "\n",
        "# Define learning rate decay function\n",
        "def lr_time_based_decay_linear(epoch, lr):\n",
        "    return lr * 1 / (1 + decay_rate * epoch / decay_steps)\n",
        "def lr_time_based_decay_exponential(epoch, lr):\n",
        "    return lr * math.exp( decay_rate * epoch / decay_steps)\n",
        "decays = [lr_time_based_decay_linear,lr_time_based_decay_exponential]\n",
        "decays_name = [\"Linear\",\"Exponential\"]\n",
        "\n",
        "# Initialize Adam optimizer with learning rate decay\n",
        "adam_optimizer = Adam(learning_rate=initial_learning_rate)\n",
        "sgd_optimizer = SGD(learning_rate=initial_learning_rate)\n",
        "rmsprop_optimizer = RMSprop(learning_rate=initial_learning_rate)\n",
        "\n",
        "optimizers = [adam_optimizer,rmsprop_optimizer,sgd_optimizer]\n",
        "optimizers_name = [\"Adam\",\"RMSprop\",\"SGD\"]\n",
        "miou_values = []\n",
        "\n",
        "for j in range(0,2):\n",
        "  for i in range(3):\n",
        "    model = SegFormer_B0(input_shape = (480, 640, 3), num_classes = 2)\n",
        "    model.compile(optimizer=optimizers[i], loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, validation_data=(X_val,y_val),batch_size=16, epochs=15, callbacks=[LearningRateScheduler(decays[j], verbose=0)])\n",
        "    model.save_weights(\"segformer_b0_\"+optimizers_name[i]+\"_\"+decays_name[j]+\".weights.h5\")\n",
        "    miou = calculate_miou(model)\n",
        "    miou_values.append(miou)\n",
        "    print(decays_name[j]+\" : \" +optimizers_name[i]+ \" -> mIoU : \" + miou + \"%\")"
      ],
      "id": "90cb1e4c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bca2b873"
      },
      "outputs": [],
      "source": [
        "loss = model.history.history['loss']\n",
        "val_loss = model.history.history['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot( loss, 'r', label='Training loss')\n",
        "plt.plot( val_loss, 'bo', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "bca2b873"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "na-9Raz_O_Kr"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "indx = random.randint(0, X_test.shape[0])\n",
        "f, axarr = plt.subplots(1,3)\n",
        "axarr[0].imshow(y_predictions[indx][:,:,1] > threshold)\n",
        "axarr[1].imshow(y_test[indx])\n",
        "axarr[2].imshow(X_test[indx])"
      ],
      "id": "na-9Raz_O_Kr"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2817.423902,
      "end_time": "2023-04-26T15:15:08.335822",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-04-26T14:28:10.911920",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}